import os
import re
import json
from typing import Dict, Any, cast, Optional
from pathlib import Path
from pysnmp.smi import builder
from app.app_logger import AppLogger
from app.plugin_loader import load_plugins
from app.default_value_plugins import get_default_value

logger = AppLogger.get(__name__)

SCHEMA_VERSION = "1.0.1"


class BehaviourGenerator:
    """Generates schema.json files from compiled MIB Python files.

    Implements the three-file architecture:
    - schema.json: Structure + initial values (generated by this class)
    - behaviour.json: Dynamic functions (optional, user-created)
    - values.json: Runtime state (created by agent at runtime)

    Output structure: {output_dir}/{MIB_NAME}/schema.json
    """

    def __init__(
        self, output_dir: str = "agent-model", load_default_plugins: bool = True
    ) -> None:
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)

        # Load plugins on initialization
        if load_default_plugins:
            loaded = load_plugins()
            logger.info(
                f"Loaded {len(loaded)} default value plugins: {', '.join(loaded)}"
            )

    def generate(
        self,
        compiled_py_path: str,
        mib_name: Optional[str] = None,
        force_regenerate: bool = True,
    ) -> str:
        """Generate schema JSON from a compiled MIB Python file.

        Creates a directory structure: {output_dir}/{MIB_NAME}/schema.json
        This follows the three-file architecture:
        - schema.json (generated, structure + initial values)
        - behaviour.json (optional, user-created, dynamic functions)
        - values.json (runtime, agent-created, current state)

        Args:
            compiled_py_path: Path to the compiled MIB .py file
            mib_name: Name of the MIB module (optional, will be parsed if not provided)
            force_regenerate: If False, skip if schema.json already exists

        Returns:
            Path to the generated schema.json file
        """

        if mib_name is None:
            mib_name = self._parse_mib_name_from_py(compiled_py_path)

        # Create MIB-specific directory (platform-agnostic)
        mib_dir = Path(self.output_dir) / mib_name
        mib_dir.mkdir(parents=True, exist_ok=True)

        json_path = mib_dir / "schema.json"

        if os.path.exists(json_path):
            if force_regenerate:
                os.remove(json_path)
            else:
                return str(json_path)

        # Extract MIB information (now includes objects and traps)
        extracted_data = self._extract_mib_info(compiled_py_path, mib_name)
        info = extracted_data.get("objects", {})
        traps = extracted_data.get("traps", {})

        # Ensure table and entry symbols are recorded with their type, and each table has at least one row
        for name, symbol_info in info.items():
            # Record type for tables and entries
            if isinstance(symbol_info, dict):
                symbol_type = symbol_info.get("type", None)
                if symbol_type == "MibTable" or symbol_type == "MibTableRow":
                    if "type" not in symbol_info:
                        symbol_info["type"] = "NoneType"
                # Always ensure the table object exists and has a 'rows' field (type-based)
                if symbol_type == "MibTable":
                    if "rows" not in symbol_info or not isinstance(
                        symbol_info["rows"], list
                    ):
                        symbol_info["rows"] = []
                    # Add at least one default row if empty
                    if not symbol_info["rows"]:
                        # Find the corresponding entry by OID structure
                        entry_info = {}
                        entry_name = None
                        expected_entry_oid = list(symbol_info["oid"]) + [1]
                        for other_name, other_data in info.items():
                            if isinstance(other_data, dict) and other_data.get("type") == "MibTableRow":
                                if list(other_data.get("oid", [])) == expected_entry_oid:
                                    entry_info = other_data
                                    entry_name = other_name
                                    break
                        
                        # Extract index columns for ALL table entries (including augmented ones)
                        # If not already present, add 'indexes' field to entry_info
                        if entry_info and "indexes" not in entry_info:
                            # Try to find index columns from the compiled MIB symbols
                            # This is a best-effort: look for setIndexNames in the compiled MIB
                            # (We assume the symbol_name is the same as entry_name)
                            try:
                                mibBuilder = builder.MibBuilder()
                                # Some tests / mocks replace `builder` with a minimal object
                                # that only exposes `MibBuilder`. Protect against missing
                                # `DirMibSource` by trying the usual call and falling back.
                                try:
                                    mibBuilder.add_mib_sources(
                                        builder.DirMibSource(
                                            os.path.dirname(compiled_py_path)
                                        )
                                    )
                                except Exception:
                                    # either DirMibSource is missing (AttributeError) or
                                    # the add call failed; call without args (mocks accept it)
                                    try:
                                        mibBuilder.add_mib_sources()
                                    except Exception:
                                        # best-effort: move on if even that fails
                                        pass
                                mibBuilder.load_modules(mib_name)
                                mib_symbols = mibBuilder.mibSymbols[mib_name]
                                entry_obj = mib_symbols.get(entry_name)
                                if entry_obj and hasattr(entry_obj, "getIndexNames"):
                                    index_names = [
                                        idx[2] for idx in entry_obj.getIndexNames()
                                    ]
                                    entry_info["indexes"] = index_names
                            except Exception as e:
                                logger.warning(
                                    f"Could not extract index columns for {entry_name}: {e}"
                                )
                        
                        # Find columns: direct children of entry OID
                        # Note: Even augmented tables (with index_from) need default rows
                        # for their non-index columns
                        entry_oid = tuple(entry_info.get("oid", []))
                        columns = []
                        for col_name, col_info in info.items():
                            if not isinstance(col_info, dict):
                                continue
                            col_oid = tuple(col_info.get("oid", []))
                            if col_name in [name, entry_name]:
                                continue
                            if (
                                len(col_oid) == len(entry_oid) + 1
                                and col_oid[: len(entry_oid)] == entry_oid
                            ):
                                columns.append(col_name)
                        # Build a default row with sensible values
                        default_row = {}
                        if not hasattr(self, "_type_registry"):
                            self._type_registry = self._load_type_registry()
                        index_names = entry_info.get("indexes", [])
                        if not index_names:
                            # Missing INDEX: introduce a faux index column for schema/state handling
                            index_names = ["__index__"]
                            entry_info["indexes"] = index_names
                        if "__index__" in index_names:
                            default_row["__index__"] = "1"

                        for col in columns:
                            col_info = info[col]
                            col_type = col_info.get("type", "")
                            type_info = self._type_registry.get(col_type, {})
                            # Add enums from col_info to type_info if present
                            if "enums" in col_info:
                                type_info = {**type_info, "enums": col_info["enums"]}
                            # If this column is an index, set appropriate default based on type
                            if col in index_names:
                                default_value = self._get_default_index_value(col_type, type_info)
                                # Ensure index values respect their type constraints
                                # For types with constraints excluding 0 (like InterfaceIndex), use 1 as minimum
                                if isinstance(default_value, int) and default_value < 1:
                                    # Check if type has constraints that exclude 0
                                    constraints = type_info.get("constraints", [])
                                    has_nonzero_constraint = any(
                                        c.get("min", 0) > 0 if isinstance(c, dict) and c.get("type") == "ValueRangeConstraint"
                                        else False
                                        for c in constraints
                                    )
                                    # Only fix to 1 if constraints require it
                                    if has_nonzero_constraint or col_type in ("InterfaceIndex",):
                                        default_value = 1
                                default_row[col] = default_value
                                # Don't set col_info["initial"] - table columns shouldn't have initial values
                            else:
                                value = self._get_default_value_from_type_info(
                                    type_info, col
                                )
                                default_row[col] = value
                                # Don't set col_info["initial"] - table columns shouldn't have initial values
                        if default_row:
                            symbol_info["rows"].append(default_row)

        # Write to JSON file (include both objects and traps)
        output_data = {
            "schema_version": SCHEMA_VERSION,
            "objects": info,
            "traps": traps,
        }
        with open(json_path, "w") as f:
            json.dump(output_data, f, indent=2)

        logger.info(f"Schema JSON written to {json_path} with {len(traps)} trap(s)")
        return str(json_path)

    def _parse_mib_name_from_py(self, compiled_py_path: str) -> str:
        """Parse the MIB name from the compiled Python file (looks for mibBuilder.exportSymbols)."""
        with open(compiled_py_path, "r", encoding="utf-8") as f:
            for line in f:
                if "mibBuilder.exportSymbols" in line:
                    m = re.search(
                        r'mibBuilder\.exportSymbols\(["\"]([A-Za-z0-9\-_.]+)["\"]', line
                    )
                    if m:
                        return m.group(1)
        # Fallback: use filename without extension
        return os.path.splitext(os.path.basename(compiled_py_path))[0]

    def _extract_mib_info(self, mib_py_path: str, mib_name: str) -> Dict[str, Any]:
        """Extract MIB symbol information from a compiled MIB Python file.

        Args:
            mib_py_path: Path to the compiled MIB .py file
            mib_name: Name of the MIB module

        Returns:
            Dictionary mapping symbol names to their metadata
        """

        mibBuilder = builder.MibBuilder()
        # Protect against minimal / mocked `builder` objects that lack DirMibSource
        try:
            mibBuilder.add_mib_sources(builder.DirMibSource(os.path.dirname(mib_py_path)))
        except Exception:
            try:
                mibBuilder.add_mib_sources()
            except Exception:
                pass
        mibBuilder.load_modules(mib_name)
        mib_symbols = mibBuilder.mibSymbols[mib_name]

        if not isinstance(mib_symbols, dict):
            mib_type = type(mib_symbols)
            mib_repr = repr(mib_symbols)[:500]
            logger.error(
                f"mib_symbols for {mib_name} is not a dict (type={mib_type}). Value: {mib_repr}"
            )
            # Place a breakpoint on the next line to inspect the value of mib_symbols
            raise TypeError(
                f"mib_symbols for {mib_name} is not a dict; cannot extract symbols."
            )

        result: Dict[str, Any] = {}
        for symbol_name, symbol_obj in mib_symbols.items():
            symbol_name_str: str = str(cast(Any, symbol_name))
            if not (
                hasattr(symbol_obj, "getName") and hasattr(symbol_obj, "getSyntax")
            ):
                continue
            try:
                oid = symbol_obj.getName()
                syntax_obj = symbol_obj.getSyntax()
                access = getattr(symbol_obj, "getMaxAccess", lambda: "unknown")()
            except TypeError:
                continue

            # Check if this is a structural type (table, row, column)
            symbol_type = symbol_obj.__class__.__name__
            is_structural = symbol_type in ("MibTable", "MibTableRow", "MibTableColumn")

            # Get the syntax type for non-structural elements
            if syntax_obj is not None and syntax_obj.__class__.__name__ != "NoneType":
                type_name = syntax_obj.__class__.__name__
            else:
                type_name = symbol_type

            if not hasattr(self, "_type_registry"):
                self._type_registry = self._load_type_registry()
            type_info = self._type_registry.get(type_name, {})

            # If type not in registry, try to infer base_type from type_name
            if not type_info and type_name:
                # Map common type names to base types
                base_type_map: Dict[str, str] = {
                    "INTEGER": "Integer32",
                    "OCTET STRING": "OctetString",
                    "OBJECT IDENTIFIER": "ObjectIdentifier",
                }
                mapped_type = base_type_map.get(type_name, type_name) or type_name
                type_info = self._type_registry.get(mapped_type, {})
                if not type_info:
                    # Create minimal type_info with base_type set to the mapped type
                    type_info = {"base_type": mapped_type}
            
            # CRITICAL: Always enrich type_info with enums from the compiled MIB syntax object
            # This is necessary because the registry has generic types (Integer32, OctetString)
            # but the actual compiled MIB has specific enums for each symbol
            if syntax_obj is not None and syntax_obj.__class__.__name__ != "NoneType":
                extracted_type_info = self._extract_type_info(syntax_obj, type_name)
                # DEBUG
                if symbol_name_str in ("ifAdminStatus", "ifOperStatus"):
                    logger.warning(f"DEBUG {symbol_name_str}: extracted enums = {extracted_type_info.get('enums')}")
                # Merge extracted enums and constraints into type_info
                # Extracted info has priority as it comes from the specific symbol
                if extracted_type_info.get("enums"):
                    type_info = dict(type_info)  # Create a copy to avoid modifying registry
                    type_info["enums"] = extracted_type_info["enums"]
                if extracted_type_info.get("constraints"):
                    type_info = dict(type_info)  # Create a copy if not already done
                    type_info["constraints"] = extracted_type_info["constraints"]

            # Provide sensible default initial values based on type
            # Skip for structural types (tables, rows, columns)
            # Table columns should NOT have initial values - they're just type definitions
            # The actual values live in the table's "rows" array
            if is_structural:
                initial_value = None
                dynamic_func = None
            else:
                initial_value = self._get_default_value_from_type_info(
                    type_info or {}, symbol_name_str
                )
                dynamic_func = self._get_dynamic_function(symbol_name_str)

            entry = {
                "oid": oid,
                "type": type_name,
                "access": access,
            }

            # Only add initial and dynamic_function for non-structural types
            # Structural types (tables, rows, columns) don't have initial values
            if not is_structural:
                entry["initial"] = initial_value
                entry["dynamic_function"] = dynamic_func
            
            # Include enums in the schema if they exist
            # This is critical for fields like ifAdminStatus that have enum constraints
            if type_info and type_info.get("enums"):
                entry["enums"] = type_info["enums"]
            
            result[symbol_name_str] = entry

        # Detect tables that inherit their index from another table (AUGMENTS pattern)
        # This needs to be done after all symbols are collected
        table_entries = {
            name: obj
            for name, obj in mib_symbols.items()
            if hasattr(obj, "getIndexNames")
        }
        self._detect_inherited_indexes(result, table_entries, mib_name)

        # Extract trap/notification definitions
        traps = self._extract_traps(mib_symbols, mib_name)
        if traps:
            logger.info(f"Found {len(traps)} trap(s) in {mib_name}: {list(traps.keys())}")
        
        logger.debug(f"Extracted MIB info for {mib_name}: {list(result.keys())}")
        return {"objects": result, "traps": traps}

    def _extract_traps(self, mib_symbols: Dict[str, Any], mib_name: str) -> Dict[str, Any]:
        """Extract NOTIFICATION-TYPE definitions from MIB symbols.
        
        Args:
            mib_symbols: Dictionary of MIB symbols from the compiled MIB
            mib_name: Name of the MIB module
            
        Returns:
            Dictionary mapping trap names to their metadata (OID, objects, description)
        """
        traps: Dict[str, Any] = {}
        
        for symbol_name, symbol_obj in mib_symbols.items():
            symbol_name_str: str = str(cast(Any, symbol_name))
            
            # Check if this is a NotificationType
            if symbol_obj.__class__.__name__ == "NotificationType":
                try:
                    # Get the OID
                    oid = symbol_obj.getName()
                    
                    # Get the OBJECTS list (varbinds that will be sent with the trap)
                    objects = []
                    if hasattr(symbol_obj, "getObjects"):
                        obj_refs = symbol_obj.getObjects()
                        if obj_refs:
                            for obj_ref in obj_refs:
                                # obj_ref is a tuple like (('IF-MIB', 'ifIndex'), ('IF-MIB', 'ifAdminStatus'))
                                if isinstance(obj_ref, tuple) and len(obj_ref) >= 2:
                                    obj_mib = str(obj_ref[0])
                                    obj_name = str(obj_ref[1])
                                    objects.append({"mib": obj_mib, "name": obj_name})
                                elif hasattr(obj_ref, "__iter__"):
                                    # Handle nested tuples
                                    for sub_ref in obj_ref:
                                        if isinstance(sub_ref, tuple) and len(sub_ref) >= 2:
                                            obj_mib = str(sub_ref[0])
                                            obj_name = str(sub_ref[1])
                                            objects.append({"mib": obj_mib, "name": obj_name})
                    
                    # Get the description if available
                    description = ""
                    if hasattr(symbol_obj, "getDescription"):
                        description = symbol_obj.getDescription() or ""
                    
                    # Get the status
                    status = "current"
                    if hasattr(symbol_obj, "getStatus"):
                        status = symbol_obj.getStatus() or "current"
                    
                    traps[symbol_name_str] = {
                        "oid": oid,
                        "objects": objects,
                        "description": description,
                        "status": status,
                        "mib": mib_name,
                    }
                    logger.debug(f"Extracted trap {symbol_name_str} with OID {oid} and {len(objects)} objects")
                except Exception as e:
                    logger.warning(f"Failed to extract trap info for {symbol_name_str}: {e}")
        
        return traps

    def _load_type_registry(self) -> Dict[str, Any]:
        """Load the canonical type registry from the exported JSON file."""
        from pathlib import Path

        registry_path = Path(__file__).resolve().parent.parent / "data" / "types.json"
        if not registry_path.exists():
            raise FileNotFoundError(
                f"Type registry JSON not found at {registry_path}. Run the type recorder/export step first."
            )
        with registry_path.open("r", encoding="utf-8") as f:
            return cast(Dict[str, Any], json.load(f))

    def _detect_inherited_indexes(
        self, result: Dict[str, Any], table_entries: Dict[str, Any], _mib_name: str
    ) -> None:
        """Detect tables that inherit their index from another table (AUGMENTS pattern).

        This is common for tables like ifXTable which AUGMENTS ifEntry from ifTable,
        inheriting ifIndex as its index without having the column in its own structure.

        Updates the result dict in-place, adding 'index_from' for entries with inherited indexes.
        """
        for entry_name, entry_obj in table_entries.items():
            try:
                index_names = entry_obj.getIndexNames()
                if not index_names:
                    continue

                # Get the table's OID to find its columns
                entry_oid = tuple(entry_obj.getName())

                # Find columns that belong to this table entry
                table_columns = set()
                for sym_name, sym_info in result.items():
                    sym_oid = tuple(sym_info["oid"])
                    # Columns are direct children of the entry (one OID component deeper)
                    if (
                        len(sym_oid) == len(entry_oid) + 1
                        and sym_oid[: len(entry_oid)] == entry_oid
                    ):
                        table_columns.add(sym_name)

                # Check if index columns are in the table's columns
                # If an index column is NOT in table_columns, it's inherited from another table
                inherited_indexes = []
                for idx_info in index_names:
                    _, idx_mib, idx_col = idx_info
                    if idx_col not in table_columns:
                        inherited_indexes.append({"mib": idx_mib, "column": idx_col})

                # Only mark as inherited if there are actually inherited index columns
                if inherited_indexes and entry_name in result:
                    result[entry_name]["index_from"] = inherited_indexes
            except Exception:
                # Skip if we can't detect - not all objects have getIndexNames
                pass

    def _extract_type_info(self, syntax_obj: Any, syntax_name: str) -> Dict[str, Any]:
        """Extract detailed type information from a syntax object.

        Returns:
            Dictionary with 'base_type', 'enums' (if applicable), 'constraints', etc.
        """
        # Determine base type by checking the class hierarchy (MRO)
        # For TextualConventions, we want the actual base SNMP type, not the TC name
        base_type = syntax_name

        # Get the class hierarchy
        mro = type(syntax_obj).__mro__

        # Look for the first base SNMP type in the hierarchy by checking class names
        # We check by name because the classes might be from different imports
        base_type_names = [
            "ObjectIdentifier",
            "OctetString",
            "Integer32",
            "Integer",
            "IpAddress",
            "Counter32",
            "Counter64",
            "Gauge32",
            "Unsigned32",
            "TimeTicks",
        ]
        for cls in mro:
            cls_name = cls.__name__
            if cls_name in base_type_names:
                base_type = cls_name
                break

        type_info: Dict[str, Any] = {
            "base_type": base_type,
            "enums": None,
            "constraints": None,
        }

        # Extract named values (enumerations)
        if hasattr(syntax_obj, "namedValues") and syntax_obj.namedValues:
            enums = {}
            for name in syntax_obj.namedValues:
                value = syntax_obj.namedValues[name]
                enums[name] = value
            if enums:
                type_info["enums"] = enums

        # Extract constraints
        if hasattr(syntax_obj, "subtypeSpec") and syntax_obj.subtypeSpec:
            constraints = []
            try:
                # Try to get values attribute (for ConstraintsUnion)
                if hasattr(syntax_obj.subtypeSpec, "values"):
                    for constraint in syntax_obj.subtypeSpec.values:
                        constraint_info = str(constraint)
                        constraints.append(constraint_info)
                else:
                    # For other constraint types, just convert to string
                    constraints.append(str(syntax_obj.subtypeSpec))
            except Exception:
                # If we can't extract constraints, just skip them
                pass
            if constraints:
                type_info["constraints"] = constraints

        return type_info
    def _get_default_index_value(self, col_type: str, type_info: Dict[str, Any]) -> Any:
        """Get an appropriate default value for an index column based on its type.
        
        For complex types like IpAddress, returns a representative value.
        For integer types, returns 1.
        """
        # Handle special SNMP types
        if col_type == "IpAddress":
            return "192.168.1.1"  # Default IP address
        if col_type == "InterfaceIndexOrZero":
            return 0
        if col_type == "InterfaceIndex":
            return 1
        elif col_type in ("Unsigned32", "Integer32", "Integer", "Gauge32"):
            # For port numbers and similar, use a more realistic default
            # Check if this might be a port based on constraints
            if type_info:
                base = type_info.get("base_type", "")
                if "port" in base.lower():
                    return 8080
            return 1
        elif col_type in ("OctetString", "DisplayString", "PhysAddress"):
            return "default"
        else:
            # Use the generic default value generator
            return self._get_default_value_from_type_info(type_info, "index")
    def _get_default_value_from_type_info(
        self, type_info: Dict[str, Any], symbol_name: str
    ) -> Any:
        """Get a sensible default value based on type info and symbol name.

        This method uses the plugin system to determine default values.
        Plugins are called in registration order until one returns a non-None value.

        Raises:
            RuntimeError: If no plugin can provide a default value for the type.
        """
        # Try to get value from plugins
        value = get_default_value(type_info, symbol_name)

        if value is not None:
            return value

        # If no plugin handled it, raise an error - this is a configuration problem
        base_type = type_info.get("base_type", "unknown")
        raise RuntimeError(
            f"No plugin provided default value for symbol '{symbol_name}' "
            f"(base_type: {base_type}). Please add a plugin to handle this type "
            f"in the plugins/ directory or ensure the type is properly registered."
        )

    def _get_default_value(self, syntax: str, symbol_name: str) -> Any:
        """Legacy method - kept for compatibility."""
        # This is now handled by _get_default_value_from_type_info
        # but kept as fallback
        if symbol_name == "sysDescr":
            return "Simple Python SNMP Agent - Demo System"
        elif symbol_name == "sysObjectID":
            return "1.3.6.1.4.1.99999"
        elif symbol_name == "sysContact":
            return "Admin <admin@example.com>"
        elif symbol_name == "sysName":
            return "my-pysnmp-agent"
        elif symbol_name == "sysLocation":
            return "Development Lab"
        elif symbol_name == "sysUpTime":
            return None  # Dynamic, handled by uptime function

        # Type-based defaults
        if syntax in ("DisplayString", "OctetString"):
            return "unset"
        elif syntax == "ObjectIdentifier":
            return "0.0"
        elif syntax in ("Integer32", "Integer", "Gauge32", "Unsigned32"):
            return 0
        elif syntax in ("Counter32", "Counter64"):
            return 0
        elif syntax == "IpAddress":
            return "0.0.0.0"
        elif syntax == "TimeTicks":
            return 0
        else:
            return None

    def _get_dynamic_function(self, symbol_name: str) -> Any:
        """Determine if this symbol should use a dynamic function."""
        if symbol_name == "sysUpTime":
            return "uptime"
        return None
